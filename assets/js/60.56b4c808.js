(window.webpackJsonp=window.webpackJsonp||[]).push([[60],{390:function(t,s,a){"use strict";a.r(s);var n=a(4),r=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h4",{attrs:{id:"什么是梯度下降"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#什么是梯度下降"}},[t._v("#")]),t._v(" 什么是梯度下降")]),t._v(" "),s("p",[t._v("梯度下降是一种优化算法，常用于训练 "),s("a",{attrs:{href:"https://www.ibm.com/topics/machine-learning",target:"_blank",rel:"noopener noreferrer"}},[t._v("机器学习"),s("OutboundLink")],1),t._v(" 模型和 "),s("a",{attrs:{href:"https://www.ibm.com/cn-zh/topics/neural-networks",target:"_blank",rel:"noopener noreferrer"}},[t._v("神经网络"),s("OutboundLink")],1),t._v("。    训练数据可以帮助这些模型不断学习，梯度下降算法中的成本函数就像是晴雨表，通过每次参数更新的迭代来衡量模型的准确度。 该模型持续调整其参数，直至该函数接近于或等于零，以使产生的误差尽可能最小。 机器学习模型的准确性经过优化后，这些模型就可以成为人工智能 (AI) 和计算机科学应用的强大工具。")]),t._v(" "),s("h4",{attrs:{id:"梯度下降算法如何工作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#梯度下降算法如何工作"}},[t._v("#")]),t._v(" 梯度下降算法如何工作")]),t._v(" "),s("p",[t._v("在我们深入研究梯度下降算法之前，回顾一下线性回归中的一些概念可能会有所帮助。 大家可能还记得直线斜率公式$y=mx+b$，其中 "),s("code",[t._v("m")]),t._v(" 表示斜率，"),s("code",[t._v("b")]),t._v("  表示直线在 y 轴上的截距。")]),t._v(" "),s("p",[t._v("大家也可能还记得在统计方法中如何绘制散点图并找到最佳拟合线的过程，这需要使用均方误差公式计算实际输出和预测输出（y 的拟合值）之间的误差。 梯度下降算法也与此类似，但它基于凸函数。")]),t._v(" "),s("p",[t._v("梯度下降算法的起点可以是我们评估性能的任意点。 我们通过这个起点求出导数（或斜率），可以用切线来观察斜率的大小。 斜率将促使一些参数更新，包括权重和偏差。 起始点处的斜率比较大，但随着新参数的生成，斜率会逐渐减小，直至达到曲线上的最低点，即收敛点。")]),t._v(" "),s("p",[t._v("与在线性回归中寻找最佳拟合线类似，梯度下降算法的目标是使成本函数最小化，即最大程度减小预测值与实际值之间的误差。 为了做到这一点，需要两个数据点 — 一个是方向，另一个是学习速率。 这些因素决定了未来迭代的偏导数计算，使其逐渐达到局部或全局最小值（即收敛点）。")]),t._v(" "),s("ul",[s("li",[s("p",[s("strong",[t._v("学习速率")]),t._v("（也称为步长或 alpha）指的是为了达到最小值所采用的步长的大小。  这通常是一个很小的值，根据成本函数的行为进行求值和更新。 较高的学习速率会产生较大的步长，存在错过最小值的风险。  相反，较低的学习速率的步长较小。  虽然较低的学习速率具有更高的精度，但迭代次数的增加会降低整体效率，因为需要更多的时间和计算才能达到最小值。")])]),t._v(" "),s("li",[s("p",[s("strong",[t._v("成本（或损失）函数")]),t._v("用于衡量实际值和预测值在当前位置的差异或误差。  它通过向模型提供反馈，使其可以调整参数以最大程度减少误差，并找到局部或全局最小值，从而提高机器学习模型的有效性。   成本函数会持续迭代，沿着最陡下降方向（负梯度）移动，直到接近或等于零。 到达此位置时，模型停止学习。 此外，虽然成本函数和损失函数这两个术语被认为是同义词，但它们之间存在细微的差别。 值得注意的是，损失函数指的是一个训练示例的误差，而成本函数计算的是整个训练集的平均误差。\n"),s("img",{attrs:{src:"/more/Pasted%20image%2020230718214532.png",alt:"avatar"}})])])]),t._v(" "),s("h4",{attrs:{id:"梯度下降算法的类型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#梯度下降算法的类型"}},[t._v("#")]),t._v(" 梯度下降算法的类型")]),t._v(" "),s("p",[t._v("梯度下降学习算法有三种类型：批量梯度下降、随机梯度下降和小批量梯度下降。")]),t._v(" "),s("h6",{attrs:{id:"批量梯度下降算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#批量梯度下降算法"}},[t._v("#")]),t._v(" 批量梯度下降算法")]),t._v(" "),s("p",[t._v("批量梯度下降算法对训练集中每个点的误差求总和， 只有在所有训练示例都评估后才更新模型。    这个过程称为一个训练周期 (training epoc)。")]),t._v(" "),s("p",[t._v("虽然这种批量处理提高了计算效率，但对于大型训练数据集而言，它仍然需要很长的处理时间，因为仍要将所有数据存储到内存中。 批量梯度下降算法通常也会产生稳定的误差梯度和收敛性，但有时在寻找局部最小值和全局最小值时，收敛点并不是最理想。")]),t._v(" "),s("h6",{attrs:{id:"随机梯度下降算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#随机梯度下降算法"}},[t._v("#")]),t._v(" 随机梯度下降算法")]),t._v(" "),s("p",[t._v("随机梯度下降算法 (SGD) 为数据集中的每个示例运行一个训练周期，并一次性更新所有训练示例的参数。  由于只需保存一个训练示例，所以可以更轻松地将它们存储在内存中。 虽然这些频繁的更新可以使计算更加详细，速度更快，但与批量梯度下降算法相比，这可能会导致计算效率下降。  随机梯度下降算法的频繁更新可能导致嘈杂梯度，但这也有助于避开局部最小值，找到全局最小值。")]),t._v(" "),s("h6",{attrs:{id:"小批量梯度下降算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#小批量梯度下降算法"}},[t._v("#")]),t._v(" 小批量梯度下降算法")]),t._v(" "),s("p",[t._v("小批量梯度下降算法结合了批量梯度下降算法和随机梯度下降算法的理念。   它将训练数据集分成小批次， 并对每批进行更新。    这种方法兼顾了批量梯度下降算法的计算效率和随机梯度下降算法的速度。")]),t._v(" "),s("h4",{attrs:{id:"挑战"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#挑战"}},[t._v("#")]),t._v(" 挑战")]),t._v(" "),s("p",[t._v("虽然梯度下降算法是优化问题的最常见方法，但其本身也面临着一些挑战。 其中包括")]),t._v(" "),s("h6",{attrs:{id:"局部最小值和鞍点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#局部最小值和鞍点"}},[t._v("#")]),t._v(" 局部最小值和鞍点")]),t._v(" "),s("p",[t._v("对于凸问题，梯度下降算法可以很容易地找到全局最小值，但出现非凸问题时，梯度下降算法很难找到全局最小值，而模型只有找到该值才能得到最好的结果。")]),t._v(" "),s("p",[t._v("上文中提到过，当成本函数的斜率等于或接近于零时，模型会停止学习。 在一些场景中，除了全局最小值外，局部最小值和鞍点也可能产生这种斜率。 在全局最小值处，成本函数的斜率在当前点的任意一侧都会增加，而局部最小值可以模拟全局最小值处的特征。 而对于鞍点，负梯度只存在于点的一侧，在一侧达到局部最大值，在另一边达到局部最小值。 它的名字来源于马鞍。")]),t._v(" "),s("p",[t._v("嘈杂梯度可以帮助梯度避开局部最小值和鞍点。")]),t._v(" "),s("h6",{attrs:{id:"消失和爆炸梯度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#消失和爆炸梯度"}},[t._v("#")]),t._v(" 消失和爆炸梯度")]),t._v(" "),s("p",[t._v("在更深层次的神经网络中，特别是在"),s("a",{attrs:{href:"https://www.ibm.com/cn-zh/topics/recurrent-neural-networks",target:"_blank",rel:"noopener noreferrer"}},[t._v("递归神经网络"),s("OutboundLink")],1),t._v("中，当使用梯度下降算法和反向传播算法训练模型时，我们还会遇到另外两个问题。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("消失梯度：")]),t._v(" 在梯度过小时发生。  当我们在反向传播过程中向后移动时，梯度将持续变小，导致网络中早期层的学习速度比后期层慢。 当这种情况发生时，权重参数会进行更新，直到它们变得微不足道 — 即等于零，这将导致算法不再学习。")]),t._v(" "),s("li",[s("strong",[t._v("爆炸梯度：")]),t._v(" 在梯度太大时会发生这种情况，导致创建的模型不稳定。  在这种情况下，模型权重会变得太大，并最终表示为 NaN。 解决这个问题的一种方法是利用降维技术，这有助于最大程度地降低模型中的复杂性。\n"),s("img",{attrs:{src:"/more/Pasted%20image%2020230718214813.png",alt:"avatar"}})])]),t._v(" "),s("h4",{attrs:{id:"tensorflow中的应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tensorflow中的应用"}},[t._v("#")]),t._v(" Tensorflow中的应用")]),t._v(" "),s("h6",{attrs:{id:"sgd"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sgd"}},[t._v("#")]),t._v(" SGD")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实例化优化方法： SGD")]),t._v("\nopt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# , momentum=0.0, nesterov=False, name="SGD"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义要调整的参数")]),t._v("\nvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义损失函数： 无参但有返回值")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算梯度，并对参数进行更新，步长为 `- learning_rate * grad`")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.9")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br")])]),s("h6",{attrs:{id:"动量梯度下降"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#动量梯度下降"}},[t._v("#")]),t._v(" 动量梯度下降")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实例化优化方法： SGD")]),t._v("\nopt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SGD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("momentum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# , momentum=0.0, nesterov=False, name="SGD"')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义要调整的参数")]),t._v("\nvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar0 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义损失函数： 无参但有返回值")]),t._v("\nloss "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第一次更新：计算梯度，并对参数进行更新，步长为 `- learning_rate * grad`")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第二次更新，并对参数进行更新，因为加入了momentum，因此步长会增加")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 展示参数更行结果")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"第一次更新步长={}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var0"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("var1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"第二次更新步长={}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var1"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("var2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 第一次更新步长=0.10000002384185791 第二次更新步长=0.18000000715255737")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br")])]),s("h6",{attrs:{id:"adagrad"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#adagrad"}},[t._v("#")]),t._v(" Adagrad")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化Adagrad优化器")]),t._v("\nopt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adagrad"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("initial_accumulator_value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("epsilon"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e-06")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义要更新的参数")]),t._v("\nvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义损失函数")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("loss")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("var "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.0")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 进行更新")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.9046538")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br")])]),s("h6",{attrs:{id:"rmsprop"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rmsprop"}},[t._v("#")]),t._v(" RMSprop")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# RMSprop 优化器：Adagrad在迭代后期由于学习率过小，难以找到最优解")]),t._v("\nopt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RMSprop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 定义要更新的参数")]),t._v("\nvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 进行更新")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.6837723")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br")])]),s("h6",{attrs:{id:"adam"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#adam"}},[t._v("#")]),t._v(" Adam")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Adam")]),t._v("\nopt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nopt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numpy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 0.90001")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])])])}),[],!1,null,null,null);s.default=r.exports}}]);