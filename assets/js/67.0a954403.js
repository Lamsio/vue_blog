(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{396:function(t,s,a){"use strict";a.r(s);var n=a(4),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h4",{attrs:{id:"_3-1-filter-过滤法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-filter-过滤法"}},[t._v("#")]),t._v(" 3.1 Filter 过滤法")]),t._v(" "),s("h6",{attrs:{id:"方差过滤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#方差过滤"}},[t._v("#")]),t._v(" 方差过滤")]),t._v(" "),s("p",[s("strong",[t._v("VarianceThreshold")]),t._v("\n通过特征本身的方差来筛选特征的类，比如一个特征本身方差很小，就表示样本在这个特征中...\n可能特征中大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有价值。\n无论接下来的特征工程要做什么，都要优先消除方差为0的特征。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" VarianceThreshold\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\nselector "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" VarianceThreshold"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("median"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 实例化，不填参数默认方差为0")]),t._v("\nx_var0 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" selector"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx_var0"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("p",[t._v("上述代码是一个简单的基于方差中位数进行筛选的案例")]),t._v(" "),s("p",[t._v("方差过滤更好的解释就是一个无视结果好坏的过滤器，他的核心思想是根据预设的阈值进行一刀切，这一刀可能能让模型的结果有正反馈（把噪音切掉了），当然也能让模型有负反馈（把核心特征切掉了），该方法的好处就是降低模型的运行时间（毕竟特征量都减少了）")]),t._v(" "),s("p",[t._v("如果一个特征的方法很小，那么意味着这个特征上很有可能有大量取值相同（例如90%都是1, 10%为0），那这一个特征的取值对于样本而言就没有区分度，这种特征就不带有有效信息，反之，如果方差很大，就意味着带有大量有效信息")]),t._v(" "),s("h6",{attrs:{id:"卡方过滤"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#卡方过滤"}},[t._v("#")]),t._v(" 卡方过滤")]),t._v(" "),s("p",[t._v("这属于相关性过滤，我们希望挑选出与标签相关并且有意义的特征，至于卡方过滤的底层原理不在此说明了，我们提供一个案例用来参考")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ensemble "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RandomForestClassifier "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" RFC\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbors "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" KNeighborsClassifier "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" KNN\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" cross_val_score\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SelectKBest\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" chi2\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n\nx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iloc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ny "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iloc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nx_fsvar "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" VarianceThreshold"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("median"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("var"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncross_val_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RFC"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_estimators"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#0.9610")]),t._v("\n\nx_fschi "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SelectKBest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chi2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx_fschi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 300")]),t._v("\ncross_val_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RFC"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_estimators"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x_fschi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#0.956928")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br")])]),s("p",[t._v("由于先前方差过滤时，我们得到了一个不错的结果，因此我们在这个案例中可以沿用那个结果，但从上面案例中可以发现，实际上使用卡方过滤后的情况更差了，这是因为卡方过滤把个别关键特征也过滤掉了，那么我们究竟该设置k为多少时比较合适呢？答案是无解。我们需要自己通过学习曲线去分析，得出自认为较好的k的取值")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\nscore "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("201")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    x_chi "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SelectKBest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chi2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cross_val_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RFC"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_estimators"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x_chi"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("201")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br")])]),s("p",[s("img",{attrs:{src:"/more/Pasted%20image%2020230707200102.png",alt:"avatar"}}),t._v("\n从结果趋势图中看到，随着k值上升，预测值也随之上升，这意味着特征对于训练而言都是有用的。\n但学习曲线的成本实在是太大了，需要花费大量时间才能得到一条趋势图，因此我们需要另一种方式更好地确定k值")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("P值")]),t._v(" "),s("th",[t._v("<=0.05或0.01")]),t._v(" "),s("th",[t._v(">0.05或0.01")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("数据差异")]),t._v(" "),s("td",[t._v("差异不是自然产生的")]),t._v(" "),s("td",[t._v("这些差异是很自然的样本误差")])]),t._v(" "),s("tr",[s("td",[t._v("相关性")]),t._v(" "),s("td",[t._v("两组数据是相关的")]),t._v(" "),s("td",[t._v("两组数据是相互独立的")])]),t._v(" "),s("tr",[s("td",[t._v("原假设")]),t._v(" "),s("td",[t._v("拒绝原假设，接受备择假设")]),t._v(" "),s("td",[t._v("接受原假设")])])])]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("chivalue"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pvalues_chi "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chi2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" chivalue"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pvalues_chi"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 392")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("基于卡方过滤的结论，我们得知，当K=392时，效果最好。")]),t._v(" "),s("h6",{attrs:{id:"f检验"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#f检验"}},[t._v("#")]),t._v(" F检验")]),t._v(" "),s("p",[t._v("F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。\n该方法既能做分类也能做回归，因此此包含"),s("code",[t._v("feature selection.f_classif (F检验分类)")]),t._v("和"),s("code",[t._v("feature_selection.f_regression")]),t._v("，其中，F检验分类用于标签是离散型变量的数据，而F检验回归用于标签是连续性变量。和卡方检验一样，这两个类都需要与"),s("code",[t._v("SelectKBest")]),t._v("一起使用，F检验在数据服从正态分布时，效果会很好，因此通常会将数据转换为正态分布的方式。")]),t._v(" "),s("p",[t._v("我们可以用F检验去检测先前得到的结论是否成立。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" f_classif\nF"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" f_classif"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.05")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 392")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("从上述代码中，我们用F检验再一次得到了相同的结果，这意味着卡方验证的猜想是准确的。")]),t._v(" "),s("h6",{attrs:{id:"互信息法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#互信息法"}},[t._v("#")]),t._v(" 互信息法")]),t._v(" "),s("p",[t._v("F检验能够捕捉每个特征与标签之间的线性关系，而互信息法能够捕捉每个特征与标签之间的任意关系（线性/非线性），它可以做回归也能做分类，包含了两个类"),s("code",[t._v("feature_selection.mutual_info_classif")]),t._v("和"),s("code",[t._v("feature_selection.mutual_info_regression")]),t._v("，互相信息法比F检验更加强大。")]),t._v(" "),s("p",[t._v("互信息法不会返回p值或者f值，他会返回“每个特征与目标之间的互信息量的估计”，关系性大则趋于1，反之为0意味着相互独立")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" mutual_info_classif "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" MIC\nresult "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MIC"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x_fsvar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nk "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 392")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("从互信息法的结论中得出，卡方和F检测的结果是正确的，既然互信息法那么厉害，为什么还要学F检测和卡方呢？因为计算量太庞大了，互信息法一小段数据跑了我2分钟，前两者几乎都是秒出结果。。。")]),t._v(" "),s("h4",{attrs:{id:"_3-2-嵌入法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-嵌入法"}},[t._v("#")]),t._v(" 3.2 嵌入法")]),t._v(" "),s("p",[s("img",{attrs:{src:"/more/Pasted%20image%2020230707210237.png",alt:"avatar"}}),t._v("\n嵌入法是一种让算法自己决定用哪些特征的方法，即，特征选择和算法训练同时进行，在此期间，各个特征会累计贡献值用于表明该特征对整体的重要性。基于此特性，嵌入法比过滤法更优秀，在性能允许的前提下，可以直接使用嵌入法（你可以理解为，穷人孩子用过滤法手动筛选特征，而富人孩子能用全自动设备自动过滤特征，哭了）")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("feature_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SelectFromModel\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ensemble "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RandomForestClassifier "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" RFC\n\nRFC_ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RFC"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_estimators"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx_embedded "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SelectFromModel"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RFC_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("threshold"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00067")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nx_embedded"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (42000,284)")]),t._v("\ncross_val_score"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("RFC_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x_embedded"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#0.9")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br")])]),s("h4",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("方法")]),t._v(" "),s("th",[t._v("描述")]),t._v(" "),s("th",[t._v("特性")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("VarianceThreshold")]),t._v(" "),s("td",[t._v("方差过滤，可输入方差闻值，返回方差大于闯值的新特征矩阵")]),t._v(" "),s("td",[t._v("看具体数据究竟是含有更多噪声还是更多有效特征一般就使用0或1来筛选也可以画学习曲线或取中位数跑模型来帮助确认")])]),t._v(" "),s("tr",[s("td",[t._v("SelectKBest")]),t._v(" "),s("td",[t._v("用来选取K个统计量结果最佳的特征，生成符合统计量要求的新特征矩阵")]),t._v(" "),s("td",[t._v("看配合使用的统计量")])]),t._v(" "),s("tr",[s("td",[t._v("chi2")]),t._v(" "),s("td",[t._v("卡方检验，专用于分类算法，捕捉相关性")]),t._v(" "),s("td",[t._v("追求p小于显著性水平的特征")])]),t._v(" "),s("tr",[s("td",[t._v("f_classif")]),t._v(" "),s("td",[t._v("F检验分类，只能捕捉线性相关性要求数据服从正态分布")]),t._v(" "),s("td",[t._v("追求p小于显著性水平的特征")])]),t._v(" "),s("tr",[s("td",[t._v("f_regression")]),t._v(" "),s("td",[t._v("F检验回归，只能捕捉线性相关性要求数据服从正态分布")]),t._v(" "),s("td",[t._v("追求p小于显著性水平的特征")])]),t._v(" "),s("tr",[s("td",[t._v("mutual info classif")]),t._v(" "),s("td",[t._v("互信息分类，可以捕捉任何相关性不能用于稀疏矩阵")]),t._v(" "),s("td",[t._v("追求互信息估计大于0的特征")])]),t._v(" "),s("tr",[s("td",[t._v("mutual info_regression")]),t._v(" "),s("td",[t._v("互信息回归，可以捕捉任何相关性不能用于稀疏矩阵")]),t._v(" "),s("td",[t._v("追求互信息估计大于0的特征")])])])])])}),[],!1,null,null,null);s.default=e.exports}}]);